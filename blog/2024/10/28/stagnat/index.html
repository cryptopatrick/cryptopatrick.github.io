<!DOCTYPE html>
<html lang="en-EN">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=60544&amp;path=livereload" data-no-instant defer></script>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta content="keyword 1, keyword 2, keyword 3" name="keywords">
<meta content="CryptoPatrick" name="author">
<meta property="og:title" content="STAGNAT - Seamless Global Nature">
<meta property="og:url" content="http://localhost:60544/blog/2024/10/28/stagnat/">
<meta property="og:description" content="">
<meta property="og:type" content="website" />


<meta property="og:image" content="http://localhost:60544/img/post-name/name.jpg" />


<title>STAGNAT | Seamless Global Nature</title>

<link rel="stylesheet" href="http://localhost:60544//css/style.css">
<link rel="stylesheet" href="http://localhost:60544//css/customcode.css">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<link rel="stylesheet"
      href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.0/build/styles/default.min.css">

</head>

<body>
<section class="section">
  <div class="container">
    <nav class="nav">

 <img src="../../../../../profile.jpg" alt="Avatar" style="margin-right: 1em" height="100px">
      <div class="nav-left" style="flex-basis: auto;">
        <a class="nav-item" href="http://localhost:60544/"><h1 class="title is-4">Seamless Global Nature</h1></a>
      <nav class="nav-item level is-mobile">
          
          
          <a class="level-item" href="http://localhost:60544/about/" style="display: flex; align-items: center;">
            
            <span class="icon" style="margin-right: 0.175em; display: flex; align-items: center;">
              <i class="fa fa-male"></i>
            </span>
            
            About Me
          </a>
          
          <a class="level-item" href="http://localhost:60544/tags/" style="display: flex; align-items: center;">
            
            <span class="icon" style="margin-right: 0.175em; display: flex; align-items: center;">
              <i class="fa fa-tags"></i>
            </span>
            
            Tags
          </a>
          
          <a class="level-item" href="https://100-days-of-vibe.vercel.app" style="display: flex; align-items: center;">
            
            <span class="icon" style="margin-right: 0.175em; display: flex; align-items: center;">
              <i class="fa fa-paper-plane"></i>
            </span>
            
            100DaysOfVibe
          </a>
          
          <a class="level-item" href="https://x.com/cryptopatrick" style="display: flex; align-items: center;">
            
            <span class="icon" style="margin-right: 0.175em; display: flex; align-items: center;">
              <i class="fa fa-twitter"></i>
            </span>
            
             
          </a>
          
          <a class="level-item" href="https://github.com/cryptopatrick?tab=repositories" style="display: flex; align-items: center;">
            
            <span class="icon" style="margin-right: 0.175em; display: flex; align-items: center;">
              <i class="fa fa-github"></i>
            </span>
            
             
          </a>
          
          <a class="level-item" href="https://www.instagram.com/cryptopatrickk/" style="display: flex; align-items: center;">
            
            <span class="icon" style="margin-right: 0.175em; display: flex; align-items: center;">
              <i class="fa fa-instagram"></i>
            </span>
            
             
          </a>
          
        </nav>
      </div>
      <div class="nav-right">
        <nav class="nav-item level is-mobile">
          
        </nav>
      </div>
    </nav>
  </div>
</section>

<section class="section">
  <div class="container">
    <h1 class="title">STAGNAT</h1>
    
    
    <h2 class="subtitle is-5">
      October 28, 2024
       by CryptoPatrick
      
        
        <span class="tags-inline" style="margin-left:0.1em;">
          
            
            <a class="tag is-link is-light" href="../../../../../tags/" style="margin-left:0.25em;"></a>
          
            
            <a class="tag is-link is-light" href="../../../../../tags/" style="margin-left:0.25em;"></a>
          
        </span>
      
      
    </h2>
    <div class="content">
      <blockquote>
<p>&ldquo;Most books should be blog posts, most blog posts should be tweets.&rdquo;</p>
</blockquote>
<p>What Does Radar Data Look Like?</p>
<p>Data drom a radar is different than any of the human senses.
In this post I&rsquo;ll discuss some of the most common types of data that is generated by &ldquo;TI mmWave radar sensors&rdquo;.</p>
<p>on-chip MCU capable of processing the sensor data into a meaningful data format before transmitting it off the device. These sensors sometimes feature additional processing components, such as</p>
<p>Hardware Accelerators</p>
<p>Digital Signal Processors</p>
<p>How is Radar Data Communicated</p>
<h2 id="frames">Frames</h2>
<p>Typically, radar data is output from the sensor in a frame. Much like a single frame from a video, a radar data frame is a group of data which is captured in a short period of time, and aggregated together to create a snapshot representing a single moment in time. A radar data frame is composed of data from all the chirps which are transmitted.</p>
<p>Similar to how the framerate of a video camera may vary, the rate at which a radar sensor generates frames is also configurable. A higher framerate will result in data that appears smoother over time as well as can reduce latency for a detection, but can come at the expense of power consumption. The maximum framerate is determined by a few factors. Firstly, the time between the start of each frame (often called the _frame periodicity) cannot be smaller than the amount of time it perform all the chirps. Additionally, the time required to process and transmit the data from a frame must be considered when evaluating the maximum framerate, although some parallelization is often possible during these steps.
Most radar frame rates will be between 1Hz - 20Hz.</p>
<h2 id="interfaces">Interfaces</h2>
<p>Once the frame of radar data in collected, the radar sensor will have to take some action with that data.</p>
<p>In some applications, this may mean just toggling a GPIO to toggle something in the system, or sending a brief message to another processor. In most example software provided by TI, the data collected in each frame will be transmitted off the chip by one of several communication protocols, so that it can be either visualized on a computer during evaluation, or so that an additional processor in the system can do any additional processing. The most common version of this is demo software utilizing a UART interface which is then fed into a UART-USB bridge on the Evaluation Module (EVM) to create a serial port which computers can easily connect to.</p>
<p>A radar sensor can communicate communicate with other devices using different protocols, such as UART, SPI, I2C, CAN-FD, and LIN. These interfaces can be used to transmit the processed radar data off the sensor to the rest of the system.</p>
<h3 id="bandwidth">Bandwidth</h3>
<p>Depending on what output data is enable and the frame rate which the device is configured to, not all interfaces will have the bandwidth to output the volume of data. For example, if “raw” adc data is being output, this volume of data will typically require a high speed interface, such as CSI2 or LVDS.</p>
<h2 id="format">Format</h2>
<p>Since most radar sensors have a programmable application MCU, the output format of the data is typically completely configurable by the application software. However, most TI demo software will follow a packet format that includes a frame header at the start of each transmitted frame, along with a list of packets referred to as TLV’s (Type, Length, Value). Each TLV will have a defined type that specifies what kind of data is in the packet, as well the packet’s size (length) before the packet’s data is sent. Figure 4 shows an example of what a frame will typically look like. Each demo software project will include information about the specific TLV’s that it natively supports in its user guide. Please refer to the Radar Toolbox for more info about the output structure.</p>
<h3 id="types-of-radar-data">Types of Radar Data</h3>
<p>Below are a few of the common types of data which can output via a radar sensor organized from “least processed” to “most processed”.</p>
<h2 id="adc-data">ADC Data</h2>
<p>Also referred to as Raw Radar Data, ADC data is the most basic form that can be exported via a radar sensor. This is the form of data which will be provided by Radar Sensors which are considered <em>Digital Front Ends</em> (DFE’s), meaning devices which have no on-chip processing capabilities.</p>
<p>ADC data is desirable when we want to develop a radar data processing algorithm from scratch.</p>
<p>However, outputting raw ADC data can be challenging due to the transmission bandwidth required. It is not unusual for raw ADC data collection to require well over 100 Mbps of bandwidth, which is beyond the capabilities of many of the communication protocols supported by the radar sensors. The amount of bandwidth needed will depend on the chirp configuration as well as the frame rate being used. The chirp configuration will determine the size of the Radar Cube, which is the data which is captured during each frame (which is often visually represented as a cube, as shown in Figure 5).</p>
<p>Typically, LVDS or CSI2 will be used to transmit this data at high speeds. Since it is not as simple to connect these interfaces to a host computer, TI also offers the DCA1000EVM which can stream this data via Ethernet. For more info on how to capture raw ADC data, please refer to the Radar Toolbox.</p>
<h2 id="range-profile">Range Profile</h2>
<p>After the sensor collects raw ADC data, typically the first step of processing done will be the Range processing via the 1D FFT. Once done, we can output the range profile as a plot of received energy over distance.</p>
<p>By looking for peaks in this graph, it can be seen what ranges objects exist at, but there will be no information on what angles these objects are located at. This means that two objects at the same range, but different angles, would be indistinguishable, and show up as one peak. This data can be used for ranging applications if no angle information is needed.</p>
<p>For more information on basic range data, please refer to the mmWave Radar Sensors: Object Versus Range application report</p>
<h2 id="point-cloud">Point Cloud</h2>
<p>The most common output for a radar sensor is a <em>point cloud</em>. A point cloud is a list of points in either cartesian or spherical coordinates which represent the detections from the sensor. These points represent areas of the observed scene which were “hot spots”. Reported points will often include their velocity info and their SNR (Signal-to-Noise-Ratio) along with the 3D coordinates of the point relative to the sensor. Figure 7 shows an example of a point cloud, where the color represents of the height of the point in 3D space. Additionally, the radial zones which are occupied can be seen at the bottom.</p>
<h3 id="cfar">CFAR</h3>
<p>Points in a point cloud are typically selected via a CFAR (Constant False Alarm Rate) algorithm.</p>
<p>Occupancy and Presence Detection</p>
<p>Many applications only rely upon a simple decision of is a person/object in this space, and this problem can be easily solved via the use of predefined zones. Several of the example projects available in the Radar Toolbox allow 3D zones to be defined which can be configured to report simple decisions based on the desired sensitivity. Zone occupancy will typically be determined by the number of points in the zone as well as the SNR of those points, while some use-cases may leverage additional parameters. Occupancy sensing can be used for applications such an localizing people within a vehicle, collision avoidance for robots, or just to wake up an appliance when someone enters a room.</p>
<p>Tracks or Targets</p>
<p>High resolution radar sensors are capable of sensing multiple reflections from real life targets, delivering a rich point cloud. With the addition of an additional processing layer, typically referred to as the tracker or GTrack, this point cloud can be used as input to localize targets (also frequently called tracks). Targets are usually identified by having a set of common properties such as position, velocity, physical dimensions, point density, and more.</p>
<p>Tracks are very helpful in taking a point cloud and translating that to real world objects based on known factors of the application. For example, tracks can be used as a way to count the number of people in a space, and to to track the motion of each individual, which might not be as apparent to a human looking at a point cloud.</p>
<p>Classifiers</p>
<p>It is possible to create efficient machine learning models which are able to classify detections coming from the radar device without the need for an external processor. This enables applications like gesture recognition and creates methods to mitigate false detections that may come from other objects.</p>
<p>Visualization</p>
<p>References</p>
<p>Radar Academy Module: Portfolio Overview
TI Application Report: mmWave Radar Sensors: Object Versus Range
TI Resource Explorer package: Radar Toolbox</p>




    </div>
    
    
  </div>
</section>

<section class="section">
  <div class="container has-text-centered">
    <p>'I write to understand as much as to be understood.' —Elie Wiesel<br> (c) 2024 CryptoPatrick</p>
  </div>
</section>

<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.0/build/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




</body>
